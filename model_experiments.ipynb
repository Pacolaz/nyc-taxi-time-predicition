{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T04:40:35.019897Z",
     "start_time": "2024-09-18T04:40:34.550087Z"
    }
   },
   "source": [
    "# Create the directory if it doesn't exist\n",
    "!mkdir -p ../data\n",
    "\n",
    "# Download files using curl\n",
    "!curl -o ../data/green_tripdata_2024-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\n",
    "!curl -o ../data/green_tripdata_2024-02.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-02.parquet"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "La sintaxis del comando no es correcta.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: Failed to open the file ../data/green_tripdata_2024-01.parquet: No \n",
      "Warning: such file or directory\n",
      "\n",
      "  0 1330k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (23) client returned ERROR on write of 16384 bytes\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: Failed to open the file ../data/green_tripdata_2024-02.parquet: No \n",
      "Warning: such file or directory\n",
      "\n",
      "  0 1253k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (23) client returned ERROR on write of 15847 bytes\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f701d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e90f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b23069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0122a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/green_tripdata_2024-01.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_train \u001B[38;5;241m=\u001B[39m read_dataframe(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/green_tripdata_2024-01.parquet\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m df_val \u001B[38;5;241m=\u001B[39m read_dataframe(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/green_tripdata_2024-02.parquet\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m, in \u001B[0;36mread_dataframe\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_dataframe\u001B[39m(filename):\n\u001B[1;32m----> 3\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_parquet(filename)\n\u001B[0;32m      5\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mlpep_dropoff_datetime \u001B[38;5;241m-\u001B[39m df\u001B[38;5;241m.\u001B[39mlpep_pickup_datetime\n\u001B[0;32m      6\u001B[0m     df\u001B[38;5;241m.\u001B[39mduration \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mduration\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m td: td\u001B[38;5;241m.\u001B[39mtotal_seconds() \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m60\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:503\u001B[0m, in \u001B[0;36mread_parquet\u001B[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001B[0m\n\u001B[0;32m    456\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001B[39;00m\n\u001B[0;32m    458\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;124;03mDataFrame\u001B[39;00m\n\u001B[0;32m    500\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    501\u001B[0m impl \u001B[38;5;241m=\u001B[39m get_engine(engine)\n\u001B[1;32m--> 503\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m impl\u001B[38;5;241m.\u001B[39mread(\n\u001B[0;32m    504\u001B[0m     path,\n\u001B[0;32m    505\u001B[0m     columns\u001B[38;5;241m=\u001B[39mcolumns,\n\u001B[0;32m    506\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m    507\u001B[0m     use_nullable_dtypes\u001B[38;5;241m=\u001B[39muse_nullable_dtypes,\n\u001B[0;32m    508\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    509\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:244\u001B[0m, in \u001B[0;36mPyArrowImpl.read\u001B[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001B[0m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    242\u001B[0m     to_pandas_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit_blocks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[1;32m--> 244\u001B[0m path_or_handle, handles, kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilesystem\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _get_path_or_handle(\n\u001B[0;32m    245\u001B[0m     path,\n\u001B[0;32m    246\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilesystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    247\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m    248\u001B[0m     mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    249\u001B[0m )\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    251\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mparquet\u001B[38;5;241m.\u001B[39mread_table(\n\u001B[0;32m    252\u001B[0m         path_or_handle, columns\u001B[38;5;241m=\u001B[39mcolumns, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    253\u001B[0m     )\u001B[38;5;241m.\u001B[39mto_pandas(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mto_pandas_kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:102\u001B[0m, in \u001B[0;36m_get_path_or_handle\u001B[1;34m(path, fs, storage_options, mode, is_dir)\u001B[0m\n\u001B[0;32m     92\u001B[0m handles \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m fs\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dir\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;66;03m# fsspec resources can also point to directories\u001B[39;00m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001B[39;00m\n\u001B[1;32m--> 102\u001B[0m     handles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[0;32m    103\u001B[0m         path_or_handle, mode, is_text\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, storage_options\u001B[38;5;241m=\u001B[39mstorage_options\n\u001B[0;32m    104\u001B[0m     )\n\u001B[0;32m    105\u001B[0m     fs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    106\u001B[0m     path_or_handle \u001B[38;5;241m=\u001B[39m handles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:865\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    857\u001B[0m             handle,\n\u001B[0;32m    858\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    861\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    862\u001B[0m         )\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n\u001B[0;32m    866\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    868\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/green_tripdata_2024-01.parquet'"
     ]
    }
   ],
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2024-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2024-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5eaa74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPU_DO\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPULocationID\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m df_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDOLocationID\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      2\u001B[0m df_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPU_DO\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPULocationID\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m df_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDOLocationID\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142ce43a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m numerical \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrip_distance\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m dv \u001B[38;5;241m=\u001B[39m DictVectorizer()\n\u001B[1;32m----> 5\u001B[0m train_dicts \u001B[38;5;241m=\u001B[39m df_train[categorical \u001B[38;5;241m+\u001B[39m numerical]\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m X_train \u001B[38;5;241m=\u001B[39m dv\u001B[38;5;241m.\u001B[39mfit_transform(train_dicts)\n\u001B[0;32m      8\u001B[0m val_dicts \u001B[38;5;241m=\u001B[39m df_val[categorical \u001B[38;5;241m+\u001B[39m numerical]\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "categorical = ['PU_DO']  #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7dbc6b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 2\u001B[0m y_train \u001B[38;5;241m=\u001B[39m df_train[target]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m      3\u001B[0m y_val \u001B[38;5;241m=\u001B[39m df_val[target]\u001B[38;5;241m.\u001B[39mvalues\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca4ca2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dagshub\n",
      "  Obtaining dependency information for dagshub from https://files.pythonhosted.org/packages/39/09/64d87ab8f3d8dbd25d45b602d2a400bf45ebeab232bc84f3a8375b269be3/dagshub-0.3.35-py3-none-any.whl.metadata\n",
      "  Downloading dagshub-0.3.35-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: PyYAML>=5 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (6.0)\n",
      "Collecting fusepy>=3 (from dagshub)\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (1.4.4)\n",
      "Requirement already satisfied: click>=8.0.4 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (8.0.4)\n",
      "Collecting httpx~=0.23.0 (from dagshub)\n",
      "  Obtaining dependency information for httpx~=0.23.0 from https://files.pythonhosted.org/packages/ac/a2/0260c0f5d73bdf06e8d3fc1013a82b9f0633dc21750c9e3f3cb1dba7bb8c/httpx-0.23.3-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: GitPython>=3.1.29 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (3.1.43)\n",
      "Collecting rich~=13.1.0 (from dagshub)\n",
      "  Obtaining dependency information for rich~=13.1.0 from https://files.pythonhosted.org/packages/55/19/8b1ed0f3ea49306b8115afe84e8e5cd92925d732260efc75e4e3e3089bf0/rich-13.1.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting dacite~=1.6.0 (from dagshub)\n",
      "  Obtaining dependency information for dacite~=1.6.0 from https://files.pythonhosted.org/packages/06/9d/11a073172d889e9e0d0ad270a1b468876c82d759af7864a8095dfc73f46d/dacite-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tenacity~=8.2.2 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (8.2.2)\n",
      "Collecting gql[requests] (from dagshub)\n",
      "  Obtaining dependency information for gql[requests] from https://files.pythonhosted.org/packages/74/fb/01a200e1c31b79690427c8e983014e4220d2652b4372a46fe4598e1d7a8e/gql-3.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting dataclasses-json (from dagshub)\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (1.5.3)\n",
      "Collecting treelib~=1.6.4 (from dagshub)\n",
      "  Obtaining dependency information for treelib~=1.6.4 from https://files.pythonhosted.org/packages/99/36/0d5a284d58dee33a738c1a77cf032a93cb978a7382497fb54f31baa0dc1a/treelib-1.6.4-py3-none-any.whl.metadata\n",
      "  Downloading treelib-1.6.4-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pathvalidate~=3.0.0 (from dagshub)\n",
      "  Obtaining dependency information for pathvalidate~=3.0.0 from https://files.pythonhosted.org/packages/8e/3f/405eedc699cea7ef0b49c04966701316f63b60ffa49e9dc6bbce5480cae7/pathvalidate-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pathvalidate-3.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (2.8.2)\n",
      "Collecting tenacity~=8.2.2 (from dagshub)\n",
      "  Obtaining dependency information for tenacity~=8.2.2 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: boto3 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub) (1.24.28)\n",
      "Collecting dagshub-annotation-converter>=0.1.0 (from dagshub)\n",
      "  Obtaining dependency information for dagshub-annotation-converter>=0.1.0 from https://files.pythonhosted.org/packages/a7/38/077cbaa6c5eca4e2030277b49703efac7a6f7feb3c51799461a3a608afe8/dagshub_annotation_converter-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading dagshub_annotation_converter-0.1.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from click>=8.0.4->dagshub) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (4.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (10.0.1)\n",
      "Collecting pydantic>=2.0.0 (from dagshub-annotation-converter>=0.1.0->dagshub)\n",
      "  Obtaining dependency information for pydantic>=2.0.0 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "     ---------------------------------------- 0.0/149.4 kB ? eta -:--:--\n",
      "     ---------- -------------------------- 41.0/149.4 kB 991.0 kB/s eta 0:00:01\n",
      "     ---------------------------- --------- 112.6/149.4 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 149.4/149.4 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (4.7.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from GitPython>=3.1.29->dagshub) (4.0.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from httpx~=0.23.0->dagshub) (2024.7.4)\n",
      "Collecting httpcore<0.17.0,>=0.15.0 (from httpx~=0.23.0->dagshub)\n",
      "  Obtaining dependency information for httpcore<0.17.0,>=0.15.0 from https://files.pythonhosted.org/packages/04/7e/ef97af4623024e8159993b3114ce208de4f677098ae058ec5882a1bf7605/httpcore-0.16.3-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3 (from httpx~=0.23.0->dagshub)\n",
      "  Obtaining dependency information for rfc3986[idna2008]<2,>=1.3 from https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from httpx~=0.23.0->dagshub) (1.2.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0 (from rich~=13.1.0->dagshub)\n",
      "  Obtaining dependency information for commonmark<0.10.0,>=0.9.0 from https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from rich~=13.1.0->dagshub) (2.15.1)\n",
      "Requirement already satisfied: six in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from treelib~=1.6.4->dagshub) (1.16.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from boto3->dagshub) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from boto3->dagshub) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from boto3->dagshub) (0.6.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/3c/78/c1de55eb3311f2c200a8b91724414b8d6f5ae78891c15d9d936ea43c3dba/marshmallow-3.22.0-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.2 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from gql[requests]->dagshub) (3.2.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.6 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from gql[requests]->dagshub) (1.8.1)\n",
      "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n",
      "  Obtaining dependency information for backoff<3.0,>=1.11.1 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from gql[requests]->dagshub) (3.5.0)\n",
      "Requirement already satisfied: requests<3,>=2.26 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from gql[requests]->dagshub) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from gql[requests]->dagshub) (1.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from pandas->dagshub) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from pandas->dagshub) (1.24.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from anyio<5,>=3.0->gql[requests]->dagshub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from botocore<1.28.0,>=1.27.28->boto3->dagshub) (1.26.16)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.0->dagshub) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (23.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.0->dagshub)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.0->dagshub)\n",
      "  Obtaining dependency information for pydantic-core==2.23.4 from https://files.pythonhosted.org/packages/2f/76/37b7e76c645843ff46c1d73e046207311ef298d3f7b2f7d8f6ac60113071/pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from requests<3,>=2.26->gql[requests]->dagshub) (2.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (0.4.3)\n",
      "Requirement already satisfied: multidict>=4.0 in c:\\users\\pacol\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.0.2)\n",
      "Downloading dagshub-0.3.35-py3-none-any.whl (247 kB)\n",
      "   ---------------------------------------- 0.0/247.5 kB ? eta -:--:--\n",
      "   ----------------------------- --------- 184.3/247.5 kB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 247.5/247.5 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading dagshub_annotation_converter-0.1.0-py3-none-any.whl (30 kB)\n",
      "Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.5/71.5 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading pathvalidate-3.0.0-py3-none-any.whl (21 kB)\n",
      "Downloading rich-13.1.0-py3-none-any.whl (238 kB)\n",
      "   ---------------------------------------- 0.0/238.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 238.4/238.4 kB 7.1 MB/s eta 0:00:00\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading treelib-1.6.4-py3-none-any.whl (18 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.1/51.1 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "   ---------------------------------------- 0.0/69.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 69.6/69.6 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB ? eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 434.9/434.9 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.9 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 74.0/74.0 kB 4.3 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Building wheels for collected packages: fusepy\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10501 sha256=6ed6a3434436961572d4e4dfb6fbbc4c10a97e6079349263cfd4fc5440e242ac\n",
      "  Stored in directory: c:\\users\\pacol\\appdata\\local\\pip\\cache\\wheels\\db\\4a\\86\\fdda91f8b8ebb0a70e4181dc2423b1f70c3c2d3bd1158685b5\n",
      "Successfully built fusepy\n",
      "Installing collected packages: rfc3986, fusepy, commonmark, typing-inspect, treelib, tenacity, rich, pydantic-core, pathvalidate, marshmallow, dacite, backoff, annotated-types, pydantic, httpcore, gql, dataclasses-json, httpx, dagshub-annotation-converter, dagshub\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.12\n",
      "    Uninstalling pydantic-1.10.12:\n",
      "      Successfully uninstalled pydantic-1.10.12\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.2\n",
      "    Uninstalling httpcore-1.0.2:\n",
      "      Successfully uninstalled httpcore-1.0.2\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "Successfully installed annotated-types-0.7.0 backoff-2.2.1 commonmark-0.9.1 dacite-1.6.0 dagshub-0.3.35 dagshub-annotation-converter-0.1.0 dataclasses-json-0.6.7 fusepy-3.0.1 gql-3.5.0 httpcore-0.16.3 httpx-0.23.3 marshmallow-3.22.0 pathvalidate-3.0.0 pydantic-2.9.2 pydantic-core-2.23.4 rfc3986-1.5.0 rich-13.1.0 tenacity-8.2.3 treelib-1.6.4 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.109.2 requires typing-extensions>=4.8.0, but you have typing-extensions 4.7.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047530d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001B[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001B[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=dabf0079-9d18-4e06-a016-d21448095b17&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=c1b8af2dd42c0e1b633497f5542e00f5c2e05556f7fcdbf0c6da3ab343404bb6\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Pacolaz\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Pacolaz\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Pacolaz/nyc-taxi-time-predicition\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"Pacolaz/nyc-taxi-time-predicition\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Pacolaz/nyc-taxi-time-predicition initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Pacolaz/nyc-taxi-time-predicition initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/Pacolaz/nyc-taxi-time-predicition.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/17 21:28:50 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/2275d465861f4be68b5709db9f27801d', creation_time=1726630130833, experiment_id='0', last_update_time=1726630130833, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "\n",
    "dagshub.init(url=\"https://dagshub.com/Pacolaz/nyc-taxi-time-predicition\", mlflow=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9822185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Client created. Use the name of the repo <span style=\"font-weight: bold\">(</span>nyc-taxi-time-predicition<span style=\"font-weight: bold\">)</span> as the name of the bucket\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Client created. Use the name of the repo \u001B[1m(\u001B[0mnyc-taxi-time-predicition\u001B[1m)\u001B[0m as the name of the bucket\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado: '../green_tripdata_2024-01.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m s3 \u001B[38;5;241m=\u001B[39m get_repo_bucket_client(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPacolaz/nyc-taxi-time-predicition\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Upload file\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m s3\u001B[38;5;241m.\u001B[39mupload_file(\n\u001B[0;32m      7\u001B[0m     Bucket\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnyc-taxi-time-predicition\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# name of the repo\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     Filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../green_tripdata_2024-01.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# local path of file to upload\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     Key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_data.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# remote path where to upload the file\u001B[39;00m\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m s3\u001B[38;5;241m.\u001B[39mupload_file(\n\u001B[0;32m     13\u001B[0m     Bucket\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnyc-taxi-time-predicition\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# name of the repo\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     Filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../green_tripdata_2024-02.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# local path of file to upload\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     Key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval_data.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# remote path where to upload the file\u001B[39;00m\n\u001B[0;32m     16\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\boto3\\s3\\inject.py:143\u001B[0m, in \u001B[0;36mupload_file\u001B[1;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Upload a file to an S3 object.\u001B[39;00m\n\u001B[0;32m    109\u001B[0m \n\u001B[0;32m    110\u001B[0m \u001B[38;5;124;03mUsage::\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03m    transfer.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m S3Transfer(\u001B[38;5;28mself\u001B[39m, Config) \u001B[38;5;28;01mas\u001B[39;00m transfer:\n\u001B[1;32m--> 143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m transfer\u001B[38;5;241m.\u001B[39mupload_file(\n\u001B[0;32m    144\u001B[0m         filename\u001B[38;5;241m=\u001B[39mFilename,\n\u001B[0;32m    145\u001B[0m         bucket\u001B[38;5;241m=\u001B[39mBucket,\n\u001B[0;32m    146\u001B[0m         key\u001B[38;5;241m=\u001B[39mKey,\n\u001B[0;32m    147\u001B[0m         extra_args\u001B[38;5;241m=\u001B[39mExtraArgs,\n\u001B[0;32m    148\u001B[0m         callback\u001B[38;5;241m=\u001B[39mCallback,\n\u001B[0;32m    149\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\boto3\\s3\\transfer.py:288\u001B[0m, in \u001B[0;36mS3Transfer.upload_file\u001B[1;34m(self, filename, bucket, key, callback, extra_args)\u001B[0m\n\u001B[0;32m    284\u001B[0m future \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_manager\u001B[38;5;241m.\u001B[39mupload(\n\u001B[0;32m    285\u001B[0m     filename, bucket, key, extra_args, subscribers\n\u001B[0;32m    286\u001B[0m )\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 288\u001B[0m     future\u001B[38;5;241m.\u001B[39mresult()\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001B[39;00m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;66;03m# client error.\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClientError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\futures.py:103\u001B[0m, in \u001B[0;36mTransferFuture.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresult\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m         \u001B[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001B[39;00m\n\u001B[0;32m    101\u001B[0m         \u001B[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001B[39;00m\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;66;03m# out of this and propagate the exception.\u001B[39;00m\n\u001B[1;32m--> 103\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mresult()\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    105\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\futures.py:266\u001B[0m, in \u001B[0;36mTransferCoordinator.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# final result.\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\tasks.py:269\u001B[0m, in \u001B[0;36mSubmissionTask._main\u001B[1;34m(self, transfer_future, **kwargs)\u001B[0m\n\u001B[0;32m    265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transfer_coordinator\u001B[38;5;241m.\u001B[39mset_status_to_running()\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;66;03m# Call the submit method to start submitting tasks to execute the\u001B[39;00m\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;66;03m# transfer.\u001B[39;00m\n\u001B[1;32m--> 269\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_submit(transfer_future\u001B[38;5;241m=\u001B[39mtransfer_future, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;66;03m# If there was an exception raised during the submission of task\u001B[39;00m\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;66;03m# there is a chance that the final task that signals if a transfer\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    281\u001B[0m \n\u001B[0;32m    282\u001B[0m     \u001B[38;5;66;03m# Set the exception, that caused the process to fail.\u001B[39;00m\n\u001B[0;32m    283\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_and_set_exception(e)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\upload.py:585\u001B[0m, in \u001B[0;36mUploadSubmissionTask._submit\u001B[1;34m(self, client, config, osutil, request_executor, transfer_future, bandwidth_limiter)\u001B[0m\n\u001B[0;32m    583\u001B[0m \u001B[38;5;66;03m# Determine the size if it was not provided\u001B[39;00m\n\u001B[0;32m    584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transfer_future\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39msize \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 585\u001B[0m     upload_input_manager\u001B[38;5;241m.\u001B[39mprovide_transfer_size(transfer_future)\n\u001B[0;32m    587\u001B[0m \u001B[38;5;66;03m# Do a multipart upload if needed, otherwise do a regular put object.\u001B[39;00m\n\u001B[0;32m    588\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m upload_input_manager\u001B[38;5;241m.\u001B[39mrequires_multipart_upload(\n\u001B[0;32m    589\u001B[0m     transfer_future, config\n\u001B[0;32m    590\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\upload.py:244\u001B[0m, in \u001B[0;36mUploadFilenameInputManager.provide_transfer_size\u001B[1;34m(self, transfer_future)\u001B[0m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprovide_transfer_size\u001B[39m(\u001B[38;5;28mself\u001B[39m, transfer_future):\n\u001B[0;32m    243\u001B[0m     transfer_future\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mprovide_transfer_size(\n\u001B[1;32m--> 244\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_osutil\u001B[38;5;241m.\u001B[39mget_file_size(transfer_future\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mcall_args\u001B[38;5;241m.\u001B[39mfileobj)\n\u001B[0;32m    245\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\utils.py:247\u001B[0m, in \u001B[0;36mOSUtils.get_file_size\u001B[1;34m(self, filename)\u001B[0m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_file_size\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[1;32m--> 247\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mgetsize(filename)\n",
      "File \u001B[1;32m<frozen genericpath>:50\u001B[0m, in \u001B[0;36mgetsize\u001B[1;34m(filename)\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] El sistema no puede encontrar el archivo especificado: '../green_tripdata_2024-01.parquet'"
     ]
    }
   ],
   "source": [
    "from dagshub import get_repo_bucket_client\n",
    "# Get a boto3.client object\n",
    "s3 = get_repo_bucket_client(\"Pacolaz/nyc-taxi-time-predicition\")\n",
    "\n",
    "# Upload file\n",
    "s3.upload_file(\n",
    "    Bucket=\"nyc-taxi-time-predicition\",  # name of the repo\n",
    "    Filename=\"../green_tripdata_2024-01.parquet\",  # local path of file to upload\n",
    "    Key=\"train_data.parquet\",  # remote path where to upload the file\n",
    ")\n",
    "\n",
    "s3.upload_file(\n",
    "    Bucket=\"nyc-taxi-time-predicition\",  # name of the repo\n",
    "    Filename=\"../green_tripdata_2024-02.parquet\",  # local path of file to upload\n",
    "    Key=\"eval_data.parquet\",  # remote path where to upload the file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d89735",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m training_dataset \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfrom_numpy(X_train\u001B[38;5;241m.\u001B[39mdata, targets\u001B[38;5;241m=\u001B[39my_train, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreen_tripdata_2024-01\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m validation_dataset \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfrom_numpy(X_val\u001B[38;5;241m.\u001B[39mdata, targets\u001B[38;5;241m=\u001B[39my_val, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreen_tripdata_2024-02\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2024-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2024-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29008c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2fe40f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mDMatrix(X_train, label\u001B[38;5;241m=\u001B[39my_train)\n\u001B[0;32m      2\u001B[0m valid \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mDMatrix(X_val, label\u001B[38;5;241m=\u001B[39my_val)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b47dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "         \n",
    "        # Tag model\n",
    "        mlflow.set_tag(\"model_family\", \"xgboost\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=10\n",
    "        )\n",
    "        \n",
    "        # Log xgboost model with artifact_path\n",
    "        mlflow.xgboost.log_model(booster, artifact_path=\"model\")\n",
    "         \n",
    "        # Predict in the val dataset\n",
    "        y_pred = booster.predict(valid)\n",
    "        \n",
    "        # Calculate metric\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        # Log performance metric\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bcd9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/17 21:36:59 INFO mlflow.tracking._tracking_service.client: 🏃 View run clean-stag-318 at: https://dagshub.com/Pacolaz/nyc-taxi-time-predicition.mlflow/#/experiments/0/runs/44771ff4993349bfb6d5cf58afb44847.\n",
      "\n",
      "2024/09/17 21:36:59 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Pacolaz/nyc-taxi-time-predicition.mlflow/#/experiments/0.\n",
      "\n",
      "job exception: name 'train' is not defined\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/17 21:37:00 INFO mlflow.tracking._tracking_service.client: 🏃 View run Xgboost Hyper-parameter Optimization at: https://dagshub.com/Pacolaz/nyc-taxi-time-predicition.mlflow/#/experiments/0/runs/713a60da64a74ca78dcaa498d2296623.\n",
      "2024/09/17 21:37:00 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Pacolaz/nyc-taxi-time-predicition.mlflow/#/experiments/0.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 14\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXgboost Hyper-parameter Optimization\u001B[39m\u001B[38;5;124m\"\u001B[39m, nested\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m      4\u001B[0m     search_space \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: scope\u001B[38;5;241m.\u001B[39mint(hp\u001B[38;5;241m.\u001B[39mquniform(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m1\u001B[39m)),\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m: hp\u001B[38;5;241m.\u001B[39mloguniform(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m0\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m42\u001B[39m\n\u001B[0;32m     12\u001B[0m     }\n\u001B[1;32m---> 14\u001B[0m     best_params \u001B[38;5;241m=\u001B[39m fmin(\n\u001B[0;32m     15\u001B[0m         fn\u001B[38;5;241m=\u001B[39mobjective,\n\u001B[0;32m     16\u001B[0m         space\u001B[38;5;241m=\u001B[39msearch_space,\n\u001B[0;32m     17\u001B[0m         algo\u001B[38;5;241m=\u001B[39mtpe\u001B[38;5;241m.\u001B[39msuggest,\n\u001B[0;32m     18\u001B[0m         max_evals\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m     19\u001B[0m         trials\u001B[38;5;241m=\u001B[39mTrials()\n\u001B[0;32m     20\u001B[0m     )\n\u001B[0;32m     21\u001B[0m     best_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(best_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     22\u001B[0m     best_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m42\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001B[0m, in \u001B[0;36mfmin\u001B[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    537\u001B[0m     fn \u001B[38;5;241m=\u001B[39m __objective_fmin_wrapper(fn)\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m allow_trials_fmin \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(trials, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfmin\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trials\u001B[38;5;241m.\u001B[39mfmin(\n\u001B[0;32m    541\u001B[0m         fn,\n\u001B[0;32m    542\u001B[0m         space,\n\u001B[0;32m    543\u001B[0m         algo\u001B[38;5;241m=\u001B[39malgo,\n\u001B[0;32m    544\u001B[0m         max_evals\u001B[38;5;241m=\u001B[39mmax_evals,\n\u001B[0;32m    545\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    546\u001B[0m         loss_threshold\u001B[38;5;241m=\u001B[39mloss_threshold,\n\u001B[0;32m    547\u001B[0m         max_queue_len\u001B[38;5;241m=\u001B[39mmax_queue_len,\n\u001B[0;32m    548\u001B[0m         rstate\u001B[38;5;241m=\u001B[39mrstate,\n\u001B[0;32m    549\u001B[0m         pass_expr_memo_ctrl\u001B[38;5;241m=\u001B[39mpass_expr_memo_ctrl,\n\u001B[0;32m    550\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    551\u001B[0m         catch_eval_exceptions\u001B[38;5;241m=\u001B[39mcatch_eval_exceptions,\n\u001B[0;32m    552\u001B[0m         return_argmin\u001B[38;5;241m=\u001B[39mreturn_argmin,\n\u001B[0;32m    553\u001B[0m         show_progressbar\u001B[38;5;241m=\u001B[39mshow_progressbar,\n\u001B[0;32m    554\u001B[0m         early_stop_fn\u001B[38;5;241m=\u001B[39mearly_stop_fn,\n\u001B[0;32m    555\u001B[0m         trials_save_file\u001B[38;5;241m=\u001B[39mtrials_save_file,\n\u001B[0;32m    556\u001B[0m     )\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trials \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    559\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(trials_save_file):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\base.py:671\u001B[0m, in \u001B[0;36mTrials.fmin\u001B[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;66;03m# -- Stop-gap implementation!\u001B[39;00m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;66;03m#    fmin should have been a Trials method in the first place\u001B[39;00m\n\u001B[0;32m    668\u001B[0m \u001B[38;5;66;03m#    but for now it's still sitting in another file.\u001B[39;00m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfmin\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fmin\n\u001B[1;32m--> 671\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fmin(\n\u001B[0;32m    672\u001B[0m     fn,\n\u001B[0;32m    673\u001B[0m     space,\n\u001B[0;32m    674\u001B[0m     algo\u001B[38;5;241m=\u001B[39malgo,\n\u001B[0;32m    675\u001B[0m     max_evals\u001B[38;5;241m=\u001B[39mmax_evals,\n\u001B[0;32m    676\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    677\u001B[0m     loss_threshold\u001B[38;5;241m=\u001B[39mloss_threshold,\n\u001B[0;32m    678\u001B[0m     trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    679\u001B[0m     rstate\u001B[38;5;241m=\u001B[39mrstate,\n\u001B[0;32m    680\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    681\u001B[0m     max_queue_len\u001B[38;5;241m=\u001B[39mmax_queue_len,\n\u001B[0;32m    682\u001B[0m     allow_trials_fmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,  \u001B[38;5;66;03m# -- prevent recursion\u001B[39;00m\n\u001B[0;32m    683\u001B[0m     pass_expr_memo_ctrl\u001B[38;5;241m=\u001B[39mpass_expr_memo_ctrl,\n\u001B[0;32m    684\u001B[0m     catch_eval_exceptions\u001B[38;5;241m=\u001B[39mcatch_eval_exceptions,\n\u001B[0;32m    685\u001B[0m     return_argmin\u001B[38;5;241m=\u001B[39mreturn_argmin,\n\u001B[0;32m    686\u001B[0m     show_progressbar\u001B[38;5;241m=\u001B[39mshow_progressbar,\n\u001B[0;32m    687\u001B[0m     early_stop_fn\u001B[38;5;241m=\u001B[39mearly_stop_fn,\n\u001B[0;32m    688\u001B[0m     trials_save_file\u001B[38;5;241m=\u001B[39mtrials_save_file,\n\u001B[0;32m    689\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001B[0m, in \u001B[0;36mfmin\u001B[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    583\u001B[0m rval\u001B[38;5;241m.\u001B[39mcatch_eval_exceptions \u001B[38;5;241m=\u001B[39m catch_eval_exceptions\n\u001B[0;32m    585\u001B[0m \u001B[38;5;66;03m# next line is where the fmin is actually executed\u001B[39;00m\n\u001B[1;32m--> 586\u001B[0m rval\u001B[38;5;241m.\u001B[39mexhaust()\n\u001B[0;32m    588\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_argmin:\n\u001B[0;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(trials\u001B[38;5;241m.\u001B[39mtrials) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001B[0m, in \u001B[0;36mFMinIter.exhaust\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexhaust\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    363\u001B[0m     n_done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrials)\n\u001B[1;32m--> 364\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_evals \u001B[38;5;241m-\u001B[39m n_done, block_until_done\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masynchronous)\n\u001B[0;32m    365\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrials\u001B[38;5;241m.\u001B[39mrefresh()\n\u001B[0;32m    366\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001B[0m, in \u001B[0;36mFMinIter.run\u001B[1;34m(self, N, block_until_done)\u001B[0m\n\u001B[0;32m    297\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpoll_interval_secs)\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;66;03m# -- loop over trials and do the jobs directly\u001B[39;00m\n\u001B[1;32m--> 300\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserial_evaluate()\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrials\u001B[38;5;241m.\u001B[39mrefresh()\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrials_save_file \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001B[0m, in \u001B[0;36mFMinIter.serial_evaluate\u001B[1;34m(self, N)\u001B[0m\n\u001B[0;32m    176\u001B[0m ctrl \u001B[38;5;241m=\u001B[39m base\u001B[38;5;241m.\u001B[39mCtrl(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrials, current_trial\u001B[38;5;241m=\u001B[39mtrial)\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 178\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdomain\u001B[38;5;241m.\u001B[39mevaluate(spec, ctrl)\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    180\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjob exception: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mstr\u001B[39m(e))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\hyperopt\\base.py:892\u001B[0m, in \u001B[0;36mDomain.evaluate\u001B[1;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[0;32m    883\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    884\u001B[0m     \u001B[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001B[39;00m\n\u001B[0;32m    885\u001B[0m     \u001B[38;5;66;03m#    either into the pyll part (self.expr)\u001B[39;00m\n\u001B[0;32m    886\u001B[0m     \u001B[38;5;66;03m#    or the normal Python part (self.fn)\u001B[39;00m\n\u001B[0;32m    887\u001B[0m     pyll_rval \u001B[38;5;241m=\u001B[39m pyll\u001B[38;5;241m.\u001B[39mrec_eval(\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpr,\n\u001B[0;32m    889\u001B[0m         memo\u001B[38;5;241m=\u001B[39mmemo,\n\u001B[0;32m    890\u001B[0m         print_node_on_error\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrec_eval_print_node_on_error,\n\u001B[0;32m    891\u001B[0m     )\n\u001B[1;32m--> 892\u001B[0m     rval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(pyll_rval)\n\u001B[0;32m    894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rval, (\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mint\u001B[39m, np\u001B[38;5;241m.\u001B[39mnumber)):\n\u001B[0;32m    895\u001B[0m     dict_rval \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mfloat\u001B[39m(rval), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m\"\u001B[39m: STATUS_OK}\n",
      "Cell \u001B[1;32mIn[25], line 13\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(params)\u001B[0m\n\u001B[0;32m      8\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mlog_params(params)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m     11\u001B[0m booster \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mtrain(\n\u001B[0;32m     12\u001B[0m     params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m---> 13\u001B[0m     dtrain\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[0;32m     14\u001B[0m     num_boost_round\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[0;32m     15\u001B[0m     evals\u001B[38;5;241m=\u001B[39m[(valid, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m'\u001B[39m)],\n\u001B[0;32m     16\u001B[0m     early_stopping_rounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m\n\u001B[0;32m     17\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Log xgboost model with artifact_path\u001B[39;00m\n\u001B[0;32m     20\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mxgboost\u001B[38;5;241m.\u001B[39mlog_model(booster, artifact_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.xgboost.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Xgboost Hyper-parameter Optimization\", nested=True):\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=Trials()\n",
    "    )\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "    \n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Log tags\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "            \"optimizer_engine\": \"hyper-opt\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Log a fit model instance\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "        \n",
    "    y_pred = booster.predict(valid)\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "        \n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab1eaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingrese el run_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'nyc-taxi-model'.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Not a proper runs:/ URI: runs://model. Runs URIs must be of the form 'runs:/<run_id>/run-relative/path/to/artifact'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m run_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIngrese el run_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m run_uri \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mruns:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 4\u001B[0m result \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mregister_model(\n\u001B[0;32m      5\u001B[0m     model_uri\u001B[38;5;241m=\u001B[39mrun_uri,\n\u001B[0;32m      6\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnyc-taxi-model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      7\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:77\u001B[0m, in \u001B[0;36mregister_model\u001B[1;34m(model_uri, name, await_registration_for, tags)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mregister_model\u001B[39m(\n\u001B[0;32m     18\u001B[0m     model_uri,\n\u001B[0;32m     19\u001B[0m     name,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     22\u001B[0m     tags: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     23\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModelVersion:\n\u001B[0;32m     24\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \n\u001B[0;32m     26\u001B[0m \u001B[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;124;03m        Version: 1\u001B[39;00m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _register_model(\n\u001B[0;32m     78\u001B[0m         model_uri\u001B[38;5;241m=\u001B[39mmodel_uri, name\u001B[38;5;241m=\u001B[39mname, await_registration_for\u001B[38;5;241m=\u001B[39mawait_registration_for, tags\u001B[38;5;241m=\u001B[39mtags\n\u001B[0;32m     79\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:109\u001B[0m, in \u001B[0;36m_register_model\u001B[1;34m(model_uri, name, await_registration_for, tags, local_model_path)\u001B[0m\n\u001B[0;32m    107\u001B[0m source \u001B[38;5;241m=\u001B[39m model_uri\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RunsArtifactRepository\u001B[38;5;241m.\u001B[39mis_runs_uri(model_uri):\n\u001B[1;32m--> 109\u001B[0m     source \u001B[38;5;241m=\u001B[39m RunsArtifactRepository\u001B[38;5;241m.\u001B[39mget_underlying_uri(model_uri)\n\u001B[0;32m    110\u001B[0m     (run_id, _) \u001B[38;5;241m=\u001B[39m RunsArtifactRepository\u001B[38;5;241m.\u001B[39mparse_runs_uri(model_uri)\n\u001B[0;32m    112\u001B[0m create_version_response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39m_create_model_version(\n\u001B[0;32m    113\u001B[0m     name\u001B[38;5;241m=\u001B[39mname,\n\u001B[0;32m    114\u001B[0m     source\u001B[38;5;241m=\u001B[39msource,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    118\u001B[0m     local_model_path\u001B[38;5;241m=\u001B[39mlocal_model_path,\n\u001B[0;32m    119\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:37\u001B[0m, in \u001B[0;36mRunsArtifactRepository.get_underlying_uri\u001B[1;34m(runs_uri)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_underlying_uri\u001B[39m(runs_uri):\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtracking\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01martifact_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_artifact_uri\n\u001B[1;32m---> 37\u001B[0m     (run_id, artifact_path) \u001B[38;5;241m=\u001B[39m RunsArtifactRepository\u001B[38;5;241m.\u001B[39mparse_runs_uri(runs_uri)\n\u001B[0;32m     38\u001B[0m     tracking_uri \u001B[38;5;241m=\u001B[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001B[0;32m     39\u001B[0m     uri \u001B[38;5;241m=\u001B[39m get_artifact_uri(run_id, artifact_path, tracking_uri)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:54\u001B[0m, in \u001B[0;36mRunsArtifactRepository.parse_runs_uri\u001B[1;34m(run_uri)\u001B[0m\n\u001B[0;32m     52\u001B[0m path \u001B[38;5;241m=\u001B[39m parsed\u001B[38;5;241m.\u001B[39mpath\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(path) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 54\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[0;32m     55\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNot a proper runs:/ URI: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_uri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     56\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRuns URIs must be of the form \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mruns:/<run_id>/run-relative/path/to/artifact\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     57\u001B[0m     )\n\u001B[0;32m     58\u001B[0m path \u001B[38;5;241m=\u001B[39m path[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m     60\u001B[0m path_parts \u001B[38;5;241m=\u001B[39m path\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mMlflowException\u001B[0m: Not a proper runs:/ URI: runs://model. Runs URIs must be of the form 'runs:/<run_id>/run-relative/path/to/artifact'"
     ]
    }
   ],
   "source": [
    "run_id = input(\"Ingrese el run_id\")\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=run_uri,\n",
    "    name=\"nyc-taxi-model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a811f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Response: {'error_code': 'RESOURCE_DOES_NOT_EXIST'}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRestException\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m model_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# create \"champion\" alias for version 1 of model \"nyc-taxi-model\"\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m client\u001B[38;5;241m.\u001B[39mset_registered_model_alias(\n\u001B[0;32m     16\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnyc-taxi-model\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m     alias\u001B[38;5;241m=\u001B[39mnew_alias,\n\u001B[0;32m     18\u001B[0m     version\u001B[38;5;241m=\u001B[39mmodel_version\n\u001B[0;32m     19\u001B[0m )\n\u001B[0;32m     21\u001B[0m client\u001B[38;5;241m.\u001B[39mupdate_model_version(\n\u001B[0;32m     22\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnyc-taxi-model\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     23\u001B[0m     version\u001B[38;5;241m=\u001B[39mmodel_version,\n\u001B[0;32m     24\u001B[0m     description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model version \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_version\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m was transitioned to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnew_alias\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     25\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\client.py:4554\u001B[0m, in \u001B[0;36mMlflowClient.set_registered_model_alias\u001B[1;34m(self, name, alias, version)\u001B[0m\n\u001B[0;32m   4552\u001B[0m _validate_model_alias_name(alias)\n\u001B[0;32m   4553\u001B[0m _validate_model_version(version)\n\u001B[1;32m-> 4554\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_registry_client()\u001B[38;5;241m.\u001B[39mset_registered_model_alias(name, alias, version)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\client.py:394\u001B[0m, in \u001B[0;36mModelRegistryClient.set_registered_model_alias\u001B[1;34m(self, name, alias, version)\u001B[0m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_registered_model_alias\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, alias, version):\n\u001B[0;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Set a registered model alias pointing to a model version.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;124;03m        None\u001B[39;00m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 394\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mset_registered_model_alias(name, alias, version)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\model_registry\\rest_store.py:442\u001B[0m, in \u001B[0;36mRestStore.set_registered_model_alias\u001B[1;34m(self, name, alias, version)\u001B[0m\n\u001B[0;32m    430\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;124;03mSet a registered model alias pointing to a model version.\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;124;03m    None\u001B[39;00m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    441\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(SetRegisteredModelAlias(name\u001B[38;5;241m=\u001B[39mname, alias\u001B[38;5;241m=\u001B[39malias, version\u001B[38;5;241m=\u001B[39mversion))\n\u001B[1;32m--> 442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(SetRegisteredModelAlias, req_body)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\model_registry\\base_rest_store.py:44\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[1;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m     endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n\u001B[0;32m     45\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n\u001B[0;32m     46\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:363\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[0m\n\u001B[0;32m    360\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m json_body\n\u001B[0;32m    361\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[1;32m--> 363\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n\u001B[0;32m    364\u001B[0m js_dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext)\n\u001B[0;32m    365\u001B[0m parse_dict(js_dict\u001B[38;5;241m=\u001B[39mjs_dict, message\u001B[38;5;241m=\u001B[39mresponse_proto)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:233\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[1;34m(response, endpoint)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n\u001B[1;32m--> 233\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    235\u001B[0m         base_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    236\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m != 200\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    238\u001B[0m         )\n",
      "\u001B[1;31mRestException\u001B[0m: RESOURCE_DOES_NOT_EXIST: Response: {'error_code': 'RESOURCE_DOES_NOT_EXIST'}"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "client.update_registered_model(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    description=\"Model registry for the NYC Taxi Time Prediction Project\",\n",
    ")\n",
    "\n",
    "new_alias = \"champion\"\n",
    "date = datetime.today()\n",
    "model_version = \"1\"\n",
    "\n",
    "# create \"champion\" alias for version 1 of model \"nyc-taxi-model\"\n",
    "client.set_registered_model_alias(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    alias=new_alias,\n",
    "    version=model_version\n",
    ")\n",
    "\n",
    "client.update_model_version(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_alias} on {date}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5717fb76",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "INVALID_PARAMETER_VALUE: Response: {'error_code': 'INVALID_PARAMETER_VALUE'}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRestException\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m alias \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchampion\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m model_uri \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00malias\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 8\u001B[0m champion_version \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m      9\u001B[0m     model_uri\u001B[38;5;241m=\u001B[39mmodel_uri\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m champion_version\u001B[38;5;241m.\u001B[39mpredict(X_val)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracing\\provider.py:253\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    251\u001B[0m disable()\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 253\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    255\u001B[0m     enable()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:1017\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(model_uri, suppress_warnings, dst_path, model_config)\u001B[0m\n\u001B[0;32m   1013\u001B[0m         entity_list\u001B[38;5;241m.\u001B[39mappend(Entity(job\u001B[38;5;241m=\u001B[39mjob_entity))\n\u001B[0;32m   1015\u001B[0m     lineage_header_info \u001B[38;5;241m=\u001B[39m LineageHeaderInfo(entities\u001B[38;5;241m=\u001B[39mentity_list) \u001B[38;5;28;01mif\u001B[39;00m entity_list \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1017\u001B[0m local_path \u001B[38;5;241m=\u001B[39m _download_artifact_from_uri(\n\u001B[0;32m   1018\u001B[0m     artifact_uri\u001B[38;5;241m=\u001B[39mmodel_uri, output_path\u001B[38;5;241m=\u001B[39mdst_path, lineage_header_info\u001B[38;5;241m=\u001B[39mlineage_header_info\n\u001B[0;32m   1019\u001B[0m )\n\u001B[0;32m   1021\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m suppress_warnings:\n\u001B[0;32m   1022\u001B[0m     model_requirements \u001B[38;5;241m=\u001B[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:108\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[1;34m(artifact_uri, output_path, lineage_header_info)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;124;03m    lineage_header_info: The model lineage header info to be consumed by lineage services.\u001B[39;00m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    107\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001B[1;32m--> 108\u001B[0m repo \u001B[38;5;241m=\u001B[39m get_artifact_repository(artifact_uri\u001B[38;5;241m=\u001B[39mroot_uri)\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(repo, ModelsArtifactRepository):\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m repo\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n\u001B[0;32m    112\u001B[0m         artifact_path\u001B[38;5;241m=\u001B[39martifact_path,\n\u001B[0;32m    113\u001B[0m         dst_path\u001B[38;5;241m=\u001B[39moutput_path,\n\u001B[0;32m    114\u001B[0m         lineage_header_info\u001B[38;5;241m=\u001B[39mlineage_header_info,\n\u001B[0;32m    115\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:132\u001B[0m, in \u001B[0;36mget_artifact_repository\u001B[1;34m(artifact_uri)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_artifact_repository\u001B[39m(artifact_uri: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ArtifactRepository:\n\u001B[0;32m    120\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;124;03m        requirements.\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 132\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _artifact_repository_registry\u001B[38;5;241m.\u001B[39mget_artifact_repository(artifact_uri)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:77\u001B[0m, in \u001B[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001B[1;34m(self, artifact_uri)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repository \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[0;32m     74\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a registered artifact repository for: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00martifact_uri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     75\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrently registered schemes are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     76\u001B[0m     )\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repository(artifact_uri)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\models_artifact_repo.py:59\u001B[0m, in \u001B[0;36mModelsArtifactRepository.__init__\u001B[1;34m(self, artifact_uri)\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mmodel_version\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     55\u001B[0m     (\n\u001B[0;32m     56\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name,\n\u001B[0;32m     57\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_version,\n\u001B[0;32m     58\u001B[0m         underlying_uri,\n\u001B[1;32m---> 59\u001B[0m     ) \u001B[38;5;241m=\u001B[39m ModelsArtifactRepository\u001B[38;5;241m.\u001B[39m_get_model_uri_infos(artifact_uri)\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m get_artifact_repository(underlying_uri)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\models_artifact_repo.py:93\u001B[0m, in \u001B[0;36mModelsArtifactRepository._get_model_uri_infos\u001B[1;34m(uri)\u001B[0m\n\u001B[0;32m     89\u001B[0m databricks_profile_uri \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     90\u001B[0m     get_databricks_profile_uri_from_artifact_uri(uri) \u001B[38;5;129;01mor\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mget_registry_uri()\n\u001B[0;32m     91\u001B[0m )\n\u001B[0;32m     92\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient(registry_uri\u001B[38;5;241m=\u001B[39mdatabricks_profile_uri)\n\u001B[1;32m---> 93\u001B[0m name, version \u001B[38;5;241m=\u001B[39m get_model_name_and_version(client, uri)\n\u001B[0;32m     94\u001B[0m download_uri \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_download_uri(name, version)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m     97\u001B[0m     name,\n\u001B[0;32m     98\u001B[0m     version,\n\u001B[0;32m     99\u001B[0m     add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri),\n\u001B[0;32m    100\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\utils\\models.py:93\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[1;34m(client, models_uri)\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, model_version\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\u001B[38;5;241m.\u001B[39mversion\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_name, \u001B[38;5;28mstr\u001B[39m(_get_latest_model_version(client, model_name, model_stage))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\client.py:4737\u001B[0m, in \u001B[0;36mMlflowClient.get_model_version_by_alias\u001B[1;34m(self, name, alias)\u001B[0m\n\u001B[0;32m   4653\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n\u001B[0;32m   4654\u001B[0m \n\u001B[0;32m   4655\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4734\u001B[0m \u001B[38;5;124;03m    Aliases: [\"test-alias\"]\u001B[39;00m\n\u001B[0;32m   4735\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4736\u001B[0m _validate_model_name(name)\n\u001B[1;32m-> 4737\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_registry_client()\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(name, alias)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\client.py:419\u001B[0m, in \u001B[0;36mModelRegistryClient.get_model_version_by_alias\u001B[1;34m(self, name, alias)\u001B[0m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model_version_by_alias\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, alias):\n\u001B[0;32m    409\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n\u001B[0;32m    410\u001B[0m \n\u001B[0;32m    411\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    417\u001B[0m \n\u001B[0;32m    418\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(name, alias)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\model_registry\\rest_store.py:470\u001B[0m, in \u001B[0;36mRestStore.get_model_version_by_alias\u001B[1;34m(self, name, alias)\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;124;03mGet the model version instance by name and alias.\u001B[39;00m\n\u001B[0;32m    461\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m    A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    469\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetModelVersionByAlias(name\u001B[38;5;241m=\u001B[39mname, alias\u001B[38;5;241m=\u001B[39malias))\n\u001B[1;32m--> 470\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(GetModelVersionByAlias, req_body)\n\u001B[0;32m    471\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ModelVersion\u001B[38;5;241m.\u001B[39mfrom_proto(response_proto\u001B[38;5;241m.\u001B[39mmodel_version)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\store\\model_registry\\base_rest_store.py:44\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[1;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m     endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n\u001B[0;32m     45\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n\u001B[0;32m     46\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:363\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[0m\n\u001B[0;32m    360\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m json_body\n\u001B[0;32m    361\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[1;32m--> 363\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n\u001B[0;32m    364\u001B[0m js_dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext)\n\u001B[0;32m    365\u001B[0m parse_dict(js_dict\u001B[38;5;241m=\u001B[39mjs_dict, message\u001B[38;5;241m=\u001B[39mresponse_proto)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:233\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[1;34m(response, endpoint)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n\u001B[1;32m--> 233\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    235\u001B[0m         base_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    236\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m != 200\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    238\u001B[0m         )\n",
      "\u001B[1;31mRestException\u001B[0m: INVALID_PARAMETER_VALUE: Response: {'error_code': 'INVALID_PARAMETER_VALUE'}"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"nyc-taxi-model\"\n",
    "alias = \"champion\"\n",
    "\n",
    "model_uri = f\"models:/{model_name}@{alias}\"\n",
    "\n",
    "champion_version = mlflow.pyfunc.load_model(\n",
    "    model_uri=model_uri\n",
    ")\n",
    "\n",
    "champion_version.predict(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
